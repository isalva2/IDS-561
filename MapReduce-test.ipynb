{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(file):\n",
    "\n",
    "    # read txt file\n",
    "    input = open(file, \"r\")\n",
    "    text = input.read()\n",
    "\n",
    "    # remove numbers and stop words\n",
    "    no_numbers = ''.join([i for i in text if not i.isdigit()]).lower()\n",
    "\n",
    "    # remove punctuations and new line char\n",
    "    import re\n",
    "    only_text = re.sub(r\"[^a-z\\s]+\", ' ', no_numbers)\n",
    "    \n",
    "    # replace multiple consecutive spaces with a single space\n",
    "    to_tokens = re.sub(r'\\s+', ' ', only_text).strip()\n",
    "    tokens = [s for s in to_tokens.strip().split() if s.strip()]\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = preprocessing(\"misc_files/List-of-Glagolitic-manuscripts-Wikipedia.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitlines(tokens: list, split=50000):\n",
    "    split1 = tokens[0:split]\n",
    "    split2 = tokens[split:]\n",
    "\n",
    "    return split1, split2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapper(text,out_queue):\n",
    "  keyval = []\n",
    "  for i in text:\n",
    "    wordssplit = i.split()\n",
    "    for j in wordssplit:\n",
    "      keyval.append([j,1])      #Appending each word in the line with 1 and storing it in [\"word\",1] format in a nested list\n",
    "  out_queue.put(keyval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortedlists(list1,list2):\n",
    "  out = list1 + list2             #Appending the two input lists into a single list\n",
    "  out.sort(key= lambda x :x[0])   #Sorting the lists based on the first element of the list which is the \"word\"\n",
    "  return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(sorted_list) :\n",
    " sort1out = []\n",
    " sort2out = []\n",
    " for i in sorted_list:\n",
    "    if i[0][0] < 'n':             #Partitioning the sorted word list into two separate lists \n",
    "      sort1out.append(i)          #with first list containing words starting with a-m and n-z into second\n",
    "    else : sort2out.append(i)\n",
    " return sort1out,sort2out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reducer(part_out1,out_queue) :\n",
    "  sum_reduced = []\n",
    "  count = 1\n",
    "  for i in range(0,len(part_out1)):\n",
    "    if i < len(part_out1)-1:\n",
    "      if part_out1[i] == part_out1[i+1]:\n",
    "       count = count+1                              #Counting the number of words\n",
    "      else : \n",
    "       sum_reduced.append([part_out1[i][0],count])  #Appending the word along with count to sum_reduced list as [\"word\",count]\n",
    "       count = 1 \n",
    "    else: sum_reduced.append(part_out1[i])          #Appending the last word to the output list    \n",
    "  out_queue.put(sum_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "def multi_thread_function(func,map1_input,map2_input):  #func is the function to be used with two threads taking two inputs map1_input and map2_input\n",
    "  my_queue1 = queue.Queue()  #Using queue to store the values of mapper output to use them in sort function\n",
    "  my_queue2 = queue.Queue()\n",
    "  t1 = threading.Thread(target=func, args=(map1_input,my_queue1)) \n",
    "  t2 = threading.Thread(target=func, args=(map2_input,my_queue2))  \n",
    "  t1.start()                 #Starting the execution of thread1\n",
    "  t2.start()                 #Starting the execution of thread2 to run simultaneously with thread1\n",
    "  t1.join()                  #Waiting for the thread1 to be completely executed\n",
    "  t2.join()                  #Waiting for the thread2 to be completely executed\n",
    "  list1out = my_queue1.get() #Getting the values from the queue into a variable to return its value\n",
    "  list2out = my_queue2.get()\n",
    "  return list1out,list2out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function(text):  \n",
    "  cleantext = preprocessing(text)\n",
    "  linessplit = splitlines(cleantext,50000)\n",
    "  mapperout = multi_thread_function(mapper,linessplit[0],linessplit[1]) \n",
    "  sortedwords = sortedlists(mapperout[0],mapperout[1])\n",
    "  slicedwords = partition(sortedwords)\n",
    "  reducerout = multi_thread_function(reducer,slicedwords[0],slicedwords[1])\n",
    "  return reducerout[0]+reducerout[1]\n",
    "\n",
    "output = main_function(\"misc_files/List-of-Glagolitic-manuscripts-Wikipedia.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
